# Frontmatter

## Abstract

Digital technologies have made vast amounts of text available to researchers, and this same technological moment has provided us with the capacity to analyze that text. The first step in that analysis is to transform texts designed for human consumption into a form a computer can analyze. Using Python and the Natural Language ToolKit (commonly called NLTK), this workshop introduces strategies to turn qualitative texts into quantitative objects. Through that process, we will present a variety of strategies for simple analysis of text-based data.

## Learning Objectives

In this workshop, you will learn the following skills:

- Identify strategies for transforming texts into numbers
- Explain what a concordance is, how to find one, and why it matters
- Compare frequency distribution of words in a text to quantify the narrative arc
- Explain what stop words are and why they are often removed
- Remove stop words in a variety of languages
- Utilize Part-of-Speech tagging to gather insights about a text
- Transform any document that you have (or have access to) in a .txt format into a text that can be analyzed computationally

## Estimated time

10 hours

## Prerequisites

- Intro to Python workshop
- Basic knowledge on Jupyter Notebook

## Contexts

### Pre-reading suggestions

- [A Beginnerâ€™s Tutorial to Jupyter Notebooks](https://towardsdatascience.com/a-beginners-tutorial-to-jupyter-notebooks-1b2f8705888a)
- [What is text analysis](https://www.scribbr.com/methodology/textual-analysis/) <!--- I don't love this one, but haven't found a better one yet -->

### Projects that use these skills

- [Short list of academic Text & Data mining projects](https://libguides.bc.edu/textdatamining/projects) 
- [Building a Simple Chatbot from Scratch in Python](https://github.com/parulnith/Building-a-Simple-Chatbot-in-Python-using-NLTK)
- [Classifying personality type by social media posts](https://github.com/TGDivy/MBTI-Personality-Classifier)

### Ethical Considerations

- In working with massive amounts of text, it is natural to lose the original context. We must be aware of that and be careful when analizing it.
- It is important to constantly question our assumptions and the indexes we are using. Numbers and graphs do not tell the story, our analysis does. We must be careful not to draw hasty and simplistic conclusions for things that are complex. Just because we found out that author A uses more unique words than author B, does it mean that A is a better writer than B?

## Resources (optional)

- [Installing Anaconda](https://github.com/DHRI-Curriculum/install/blob/master/sections/python.md)
- [Installing NLTK](https://github.com/DHRI-Curriculum/install/blob/master/sections/nltk.md)
- [Jupyter Notebook shortcuts, tips and tricks](http://maxmelnick.com/2016/04/19/python-beginner-tips-and-tricks.html)

## Acknowledgements

- [Michelle McSweeney](https://github.com/michellejm)
- [Rachel Rakov](https://github.com/rachelrakov)
- [Rafael Davis Portela](https://github.com/rafadavis)
- [Kalle Westerling](https://github.com/kallewesterling)
- [Patrick Smyth](https://github.com/smythp)
- [Hannah Aizenman](https://github.com/story645)
- [Lisa Rhody](https://github.com/lmrhody)
- [Kelsey Chatlosh](https://github.com/kchatlosh)
- [Filipa Calado](https://github.com/gofilipa)